{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Bill Shock Overage / Credit\n",
    "\n",
    "This is an brief analysis of Bill Shock Overage/credit to address the business concern of EBITDA leakage.\n",
    "\n",
    "\n",
    "### Definitions:\n",
    " \n",
    "\n",
    "**Bill Overage**: the pay per use charge that wireless customers incur when they use voice/text/data above what is included in their rate plan or add-on features. For example, a customers’ rate plan includes unlimited Canada to Canada voice minutes. If the customer choses to make phone calls when they are travelling outside of Canada they will incur a roaming voice overage charge.\n",
    "\n",
    " \n",
    "\n",
    "**Bill Shock Credit**: Refund provided to the customer by a TELUS representative when they contest their bill.  \n",
    "\n",
    "\n",
    "### Case:\n",
    " \n",
    "Based on preliminary analysis we have a hypothesis that bill shock credits do not adhere to The TELUS credit policy provided below:\n",
    "\n",
    "```\n",
    " -  <$1000       overage:  25% - 50% credit,\n",
    " -   $1000-$5000 overage:  up to 50% credit,\n",
    " -  >$5000       overage:  up to 80% credit. \n",
    "```\n",
    "\n",
    "When TELUS representatives do not adhere to the credit policy TELUS incurs EBITDA ‘leakage’.  Opportunity could range from several hundred thousand dollars to several million in incremental EBITDA across all business segments. \n",
    " \n",
    "### Request:\n",
    " \n",
    "Please analyse the data provided for the “SMALL BUSINESS SOLUTION” and “TELUS BUSINESS SOLUTION” and answer:\n",
    " \n",
    "1.      Is the hypothesis correct?  If so, what is the size of the EBITDA leakage in each segment?\n",
    "2.      Is there a trend in the overage and/or credits provided?\n",
    "3.      What is the highest source of bill overage?  Is it correlated to the bill shock credits provided?\n",
    "4.      What recommendations would you suggest to address any possible revenue leakage identified.\n",
    " \n",
    " \n",
    "There are 4 worksheets in the Excel document:\n",
    " \n",
    "Read me: Field descriptions\n",
    "Revenue_overage: Overage revenue by subscriber\n",
    "Segment: Segment data\n",
    "Credits: Amount of credits by subscriber\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Content\n",
    "\n",
    "- Scope\n",
    "- Assumptions\n",
    "- Preparation\n",
    "- Solutions\n",
    "- Result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "\n",
    "1.  All credit applied to the bill within same month.\n",
    "  Say, all credits given between 2014-03-01 and 2014-03-31 will apply to the bill with CCYYMM = 201403.\n",
    "2. We only consider the scenario that more credit was given as per the policy. \n",
    "3. We do not consider the scenario that credit given below the lower limit as per the policy.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "In this section, we will load data into pandas from given excel file, as well as some cleanup process described below:\n",
    "\n",
    "- Review data set and confirm it's align with excel file\n",
    "- Check data type for each fields \n",
    "- Fill all NA with 0\n",
    "- Set Index for each dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load given excel file \n",
    "readme = pd.read_excel('test_ROAM_OVERAGE v2.xlsx',sheet_name = 'Read me')\n",
    "Revenue_Overage = pd.read_excel('test_ROAM_OVERAGE v2.xlsx',sheet_name='Revenue_Overage')\n",
    "Segment = pd.read_excel('test_ROAM_OVERAGE v2.xlsx',sheet_name='Segment')\n",
    "Credits = pd.read_excel('test_ROAM_OVERAGE v2.xlsx',sheet_name='Credits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the data and make sure they are align with excel file \n",
    "Revenue_Overage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data type for the three sheets \n",
    "Revenue_Overage.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. \n",
    "\n",
    "Now let's fill NA with 0 in datafram Revenue_Overage and set index for each dataframes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue_Overage.fillna(0, inplace = True)\n",
    "# Revenue_Overage.set_index(['MOBILE_PHONE_NO','CCYYMM'], inplace=True)\n",
    "Revenue_Overage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment.set_index('BAN', inplace=True)\n",
    "Segment.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dataframe Credits, we need more work at this stage, for we want to use the \n",
    "**credit date** as index with **'yyyymm'** format to align with Revenue_Overage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits['CCYYMM'] = Credits['ADJ_CREATION_DATE'].dt.strftime('%Y%m').astype(int)\n",
    "# Credits.set_index(['MOBILE_PHONE_NO','CCYYMM'], inplace=True)\n",
    "Credits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Solution\n",
    "\n",
    "\n",
    "In this section, we will answer the four questions:\n",
    "\n",
    "1.      Is the hypothesis correct?  If so, what is the size of the EBITDA leakage in each segment?\n",
    "2.      Is there a trend in the overage and/or credits provided?\n",
    "3.      What is the highest source of bill overage?  Is it correlated to the bill shock credits provided?\n",
    "4.      What recommendations would you suggest to address any possible revenue leakage identified.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Is the hypothesis correct?\n",
    "\n",
    "If so, what is the size of the EBITDA leakage in each segment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it simple, we enlarge the upper limit calculation by adding all the fees together and apply the overage policy. The result would be beyond the maximum credit. Also we add up all credits under same phone no for the same bill timewindow, regardless the REASON_CODE, and compare   the leakage \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate the total amount of each bill, as well as the credit upper limit; <br>\n",
    "Step 2: Aggregate the total credit for each phone number at each billing month period; <br>\n",
    "Step 3: Join the above data set by phone number and billing month, flag each row as one of the following category:<br>\n",
    "   - 'N': Normal, credit given is bellow the upper limit; \n",
    "   - 'U': Exception, credit given exceed the upper limit;\n",
    "   - 'L': Exception, credit given below the lower limit;\n",
    "   - '-': Not applicable, no credit given at all \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Overage = Revenue_Overage[['MOBILE_PHONE_NO','CCYYMM','BAN']].copy()\n",
    "\n",
    "Total_Overage['Total Amount'] = Revenue_Overage[Revenue_Overage.columns[3:]].sum(axis=1)\n",
    "\n",
    "Total_Overage['Upper Limit'] = Total_Overage.apply(\n",
    "    lambda x: round(x['Total Amount'] * 0.5,2) if x['Total Amount']<=5000 \n",
    "         else round(x['Total Amount']*.8, 2)\n",
    "               , axis = 1)\n",
    "\n",
    "Total_Overage['Lower Limit'] = Total_Overage.apply(\n",
    "    lambda x: round(x['Total Amount'] * 0.2, 2)  if x['Total Amount']< 1000 else 0, axis = 1)\n",
    "\n",
    "Total_Overage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Credit=Credits.groupby(['MOBILE_PHONE_NO','CCYYMM']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Credit.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overage_Credit = pd.merge(Total_Overage, Total_Credit, \n",
    "                          on = ['MOBILE_PHONE_NO','CCYYMM'], \n",
    "                          how='left'\n",
    "                         )\n",
    "\n",
    "Overage_Credit['Leakage'] = Overage_Credit.apply(\n",
    "    lambda x: pd.NA if pd.isna(x['ACTV_AMT']) else \n",
    "              x['ACTV_AMT'] - x['Upper Limit'] if x['ACTV_AMT']>x['Upper Limit'] else \n",
    "              x['Lower Limit'] - x['ACTV_AMT'] if x['ACTV_AMT']<x['Lower Limit'] else  \n",
    "              0 ,\n",
    "   axis = 1 )\n",
    "\n",
    "Overage_Credit['Flag'] = Overage_Credit.apply(\n",
    "    lambda x: '-' if pd.isna(x['ACTV_AMT']) else \n",
    "              'U' if x['ACTV_AMT']>x['Upper Limit'] else \n",
    "              'L' if x['ACTV_AMT']<x['Lower Limit'] else\n",
    "              'N',\n",
    "   axis = 1 )\n",
    "Overage_Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overage_Credit[['Flag','Leakage']].groupby('Flag').agg(['sum','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8439+1606+270\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "\n",
    "Since we have $1,580,131 total leakage upon 8349 over total 10315 claims, we are confident that the hypothesis is True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tell the size of leakage in each segment, we need join the Overage_Credit dataframe with the datafram Segment on 'BAN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overage_Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakages = Overage_Credit[Overage_Credit['Flag'] == 'U']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakage_segment = pd.merge(leakages[['BAN','Leakage']], Segment, \n",
    "                           on = ['BAN'] )[['RPT_SVP','Leakage']] \\\n",
    "                   .groupby('RPT_SVP').sum()   \\\n",
    "                    .sort_values('Leakage', ascending=False)\n",
    "leakage_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakage_segment.plot.pie( y= 'Leakage', legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".groupby('RPT_SVP').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code will insert the data into Postgres, it should be run ONCE ONLY\n",
    "```python\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('postgresql://yubin:DataSci2020@localhost/telus_test')\n",
    "# \n",
    "# readme.to_sql('readme', engine)\n",
    "# Revenue_Overage.to_sql('Revenue_Overage', engine)\n",
    "# Segment.to_sql('Segment', engine)\n",
    "# Credits.to_sql('Credits', engine)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"telus_test\",\n",
    "    \"user\"      : \"yubin\",\n",
    "    \"password\"  : \"DataSci2020\"\n",
    "}\n",
    "\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "\n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def postgresql_to_dataframe(conn, select_query, column_names):\n",
    "    \"\"\"\n",
    "    Tranform a SELECT query into a pandas dataframe\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    \n",
    "    # Naturally we get a list of tupples\n",
    "    tupples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    \n",
    "    # We just need to turn it into a pandas dataframe\n",
    "    df = pd.DataFrame(tupples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(param_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Total_count','Distinct_Ban_Count','Distinct_Phone_no']\n",
    "sql_str = 'select count(1), count(distinct \"BAN\") , count(distinct \"MOBILE_PHONE_NO\")  from \"Revenue_Overage\"'\n",
    "df = postgresql_to_dataframe(conn, sql_str, column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Credit_date','Credit Amt']\n",
    "sql_str = '''select \"ADJ_CREATION_DATE\" , round(sum(\"ACTV_AMT\")) \n",
    "from \"Credits\" c2  \n",
    "group by \"ADJ_CREATION_DATE\" \n",
    "order by 1'''\n",
    "\n",
    "credit_trend = postgresql_to_dataframe(conn, sql_str, column_names)\n",
    "credit_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_trend['Credit Amt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "'DATA_ROAM_AMT_USA':             'OGWRD',\n",
    "'DATA_BILLED_AMT_CDA':           'OGWDD',\n",
    "'DATA_ROAM_AMT_INTL':            'OGWRDI',\n",
    "'VOICE_ROAM_USA_AIR_CHRG_AMT':   'OGWRV',\n",
    "'VOICE_ROAM_INTL_AIR_CHRG_AMT':  'OGWRVI',\n",
    "'VOICE_ROAM_USA_LD_CHRG_AMT':    'OGWVLD',\n",
    "'VOICE_ROAM_USA_AIR_CHRG_AMT':   'OGWVA',\n",
    "'SMS_ROAM_AMOUNT':               'OGWTUS',\n",
    "'SMS_TOTAL_AMOUNT':              'OGWT',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credits['ACTV_REASON_DESCRIPTION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Total_count','Distinct_Ban_Count','Distinct_Phone_no']\n",
    "sql_str = 'select count(1), count(distinct \"BAN\") , count(distinct \"MOBILE_PHONE_NO\")  from \"Revenue_Overage\"'\n",
    "df = postgresql_to_dataframe(conn, sql_str, column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['BAN','Trans_Count', 'Total_AMT',]\n",
    "sql_str = 'select \"BAN\", count(1), sum()   from \"Revenue_Overage\"'\n",
    "df = postgresql_to_dataframe(conn, sql_str, column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue_Overage.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue_Overage['TOTAL_BILL_AMT'] = Revenue_Overage[Revenue_Overage.columns[3:]].sum(axis=1, numeric_only=True)\n",
    "Revenue_Overage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue_Overage.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue_Overage.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
